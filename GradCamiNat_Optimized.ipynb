{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install open_clip_torch\n",
        "!pip install pyinaturalist\n",
        "!pip install captum\n",
        "!pip install pybioclip\n",
        "!pip install scikit-image\n",
        "!pip install matplotlib\n",
        "!pip install scipy\n",
        "!pip install torchcam\n",
        "\n"
      ],
      "metadata": {
        "id": "dVjSNG9jZmfI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "YXtqI1iFZW7M",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b3a2ce4f-6092-4c76-909e-a30bc9ff4bb8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Processed image 1/100: images/249043966.jpg\n",
            "iNaturalist taxon: Panthera leo\n",
            "BioCLIP species: Panthera leo\n",
            "BioCLIP family: Felidae\n",
            "\n",
            "\n",
            "Processed image 2/100: images/249042871.jpg\n",
            "iNaturalist taxon: Panthera leo leo\n",
            "BioCLIP species: Cryptoprocta ferox\n",
            "BioCLIP family: Eupleridae\n",
            "\n",
            "\n",
            "Processed image 4/100: images/249028299.jpg\n",
            "iNaturalist taxon: Panthera leo leo\n",
            "BioCLIP species: Panthera leo\n",
            "BioCLIP family: Felidae\n",
            "\n",
            "\n",
            "Processed image 5/100: images/249023394.jpg\n",
            "iNaturalist taxon: Panthera\n",
            "BioCLIP species: Panthera pardus\n",
            "BioCLIP family: Felidae\n",
            "\n",
            "\n",
            "Processed image 6/100: images/249018218.jpg\n",
            "iNaturalist taxon: Panthera leo melanochaita\n",
            "BioCLIP species: Panthera leo\n",
            "BioCLIP family: Felidae\n",
            "\n",
            "\n",
            "Processed image 7/100: images/248965483.jpg\n",
            "iNaturalist taxon: Panthera leo\n",
            "BioCLIP species: Panthera leo\n",
            "BioCLIP family: Felidae\n",
            "\n",
            "\n",
            "Processed image 8/100: images/248952882.jpg\n",
            "iNaturalist taxon: Panthera leo melanochaita\n",
            "BioCLIP species: Panthera leo\n",
            "BioCLIP family: Felidae\n",
            "\n",
            "\n",
            "Processed image 9/100: images/248952732.jpg\n",
            "iNaturalist taxon: Panthera leo melanochaita\n",
            "BioCLIP species: Panthera leo\n",
            "BioCLIP family: Felidae\n",
            "\n",
            "\n",
            "Processed image 10/100: images/248946227.jpg\n",
            "iNaturalist taxon: Panthera leo\n",
            "BioCLIP species: Panthera leo\n",
            "BioCLIP family: Felidae\n",
            "\n",
            "\n",
            "Processed image 11/100: images/248946217.jpg\n",
            "iNaturalist taxon: Panthera leo\n",
            "BioCLIP species: Panthera leo\n",
            "BioCLIP family: Felidae\n",
            "\n",
            "\n",
            "Processed image 12/100: images/248946138.jpg\n",
            "iNaturalist taxon: Panthera leo\n",
            "BioCLIP species: Panthera tigris\n",
            "BioCLIP family: Felidae\n",
            "\n",
            "\n",
            "Processed image 13/100: images/248919818.jpg\n",
            "iNaturalist taxon: Panthera leo\n",
            "BioCLIP species: Panthera leo\n",
            "BioCLIP family: Felidae\n",
            "\n",
            "\n",
            "Processed image 14/100: images/248884168.jpg\n",
            "iNaturalist taxon: Panthera leo melanochaita\n",
            "BioCLIP species: Panthera leo\n",
            "BioCLIP family: Felidae\n",
            "\n",
            "\n",
            "Processed image 15/100: images/248880946.jpg\n",
            "iNaturalist taxon: Panthera leo melanochaita\n",
            "BioCLIP species: Panthera leo\n",
            "BioCLIP family: Felidae\n",
            "\n",
            "\n",
            "Processed image 16/100: images/248875908.jpg\n",
            "iNaturalist taxon: Panthera leo\n",
            "BioCLIP species: Cervus eldi\n",
            "BioCLIP family: Cervidae\n",
            "\n",
            "\n",
            "Processed image 17/100: images/248869809.jpg\n",
            "iNaturalist taxon: Panthera leo\n",
            "BioCLIP species: Panthera leo\n",
            "BioCLIP family: Felidae\n",
            "\n",
            "\n",
            "Processed image 18/100: images/248869069.jpg\n",
            "iNaturalist taxon: Panthera leo melanochaita\n",
            "BioCLIP species: Panthera leo\n",
            "BioCLIP family: Felidae\n",
            "\n",
            "\n",
            "Processed image 19/100: images/248867641.jpg\n",
            "iNaturalist taxon: Panthera leo melanochaita\n",
            "BioCLIP species: Panthera leo\n",
            "BioCLIP family: Felidae\n",
            "\n",
            "\n",
            "Processed image 20/100: images/248851574.jpg\n",
            "iNaturalist taxon: Panthera leo\n",
            "BioCLIP species: Panthera leo\n",
            "BioCLIP family: Felidae\n",
            "\n",
            "\n",
            "Processed image 21/100: images/248839636.jpg\n",
            "iNaturalist taxon: Panthera\n",
            "BioCLIP species: Panthera tigris\n",
            "BioCLIP family: Felidae\n",
            "\n",
            "\n",
            "Processed image 22/100: images/248833674.jpg\n",
            "iNaturalist taxon: Panthera\n",
            "BioCLIP species: Panthera tigris\n",
            "BioCLIP family: Felidae\n",
            "\n",
            "\n",
            "Processed image 23/100: images/248828828.jpg\n",
            "iNaturalist taxon: Panthera leo melanochaita\n",
            "BioCLIP species: Panthera leo\n",
            "BioCLIP family: Felidae\n",
            "\n",
            "\n",
            "Processed image 24/100: images/248800579.jpg\n",
            "iNaturalist taxon: Panthera leo\n",
            "BioCLIP species: Papio papio\n",
            "BioCLIP family: Cercopithecidae\n",
            "\n",
            "\n",
            "Processed image 25/100: images/248793453.jpg\n",
            "iNaturalist taxon: Panthera leo\n",
            "BioCLIP species: Panthera leo\n",
            "BioCLIP family: Felidae\n",
            "\n",
            "\n",
            "Processed image 26/100: images/248732251.jpg\n",
            "iNaturalist taxon: Panthera leo\n",
            "BioCLIP species: Felis margarita\n",
            "BioCLIP family: Felidae\n",
            "\n",
            "\n",
            "Processed image 27/100: images/248719154.jpg\n",
            "iNaturalist taxon: Panthera leo melanochaita\n",
            "BioCLIP species: Panthera leo\n",
            "BioCLIP family: Felidae\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-4f0ea30abfc0>\u001b[0m in \u001b[0;36m<cell line: 87>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    117\u001b[0m             \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad_cam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m             \u001b[0mgrad_cam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mcam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad_cam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_cam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             )\n\u001b[0;32m--> 581\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    582\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    826\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import os\n",
        "import gc  # Import garbage collector\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import torch\n",
        "import open_clip\n",
        "import numpy as np\n",
        "from skimage.transform import resize\n",
        "from pyinaturalist import get_observations, Observation\n",
        "from bioclip import TreeOfLifeClassifier, Rank\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Mount Google Drive (for saving outputs)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Initialize the model and preprocess functions\n",
        "model, preprocess_train, _ = open_clip.create_model_and_transforms('hf-hub:imageomics/bioclip')\n",
        "\n",
        "# Define the class labels to index\n",
        "class_labels_to_index = {}\n",
        "\n",
        "# Fetch observations from iNaturalist\n",
        "SPECIES = \"Panthera leo\"\n",
        "IMAGES_DIR = \"images\"\n",
        "OUTPUT_DIR = \"/content/drive/My Drive/GradCam\"\n",
        "os.makedirs(IMAGES_DIR, exist_ok=True)\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)  # Create output directory if it doesn't exist\n",
        "MAX_IMAGES = 100\n",
        "\n",
        "response = get_observations(taxon_name=SPECIES, per_page=MAX_IMAGES, has_photos=True)\n",
        "observations = Observation.from_json_list(response['results'])\n",
        "\n",
        "# Initialize the BioCLIP classifier\n",
        "classifier = TreeOfLifeClassifier()\n",
        "\n",
        "# Define Grad-CAM class with hook removal\n",
        "class GradCAM:\n",
        "    def __init__(self, model):\n",
        "        self.model = model\n",
        "        self.model.eval()\n",
        "        self.gradients = None\n",
        "        self.activations = None\n",
        "        self.hooks = []\n",
        "\n",
        "    def save_gradients(self, grad):\n",
        "        self.gradients = grad.detach()  # Detach gradients to save memory\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Remove previous hooks to prevent accumulation\n",
        "        self._remove_hooks()\n",
        "\n",
        "        # Register hook to save activations\n",
        "        def hook_fn(module, input, output):\n",
        "            self.activations = output.detach()\n",
        "            self.gradients = None  # Clear previous gradients\n",
        "\n",
        "        # Register forward hooks for Conv2d layers only once\n",
        "        for name, module in self.model.named_modules():\n",
        "            if isinstance(module, torch.nn.Conv2d):\n",
        "                hook = module.register_forward_hook(hook_fn)\n",
        "                self.hooks.append(hook)\n",
        "\n",
        "        x = self.model(x)\n",
        "        return x\n",
        "\n",
        "    def generate_cam(self, class_idx):\n",
        "        # Compute weights and CAM\n",
        "        grads = self.gradients\n",
        "        activations = self.activations\n",
        "        weights = torch.mean(grads, dim=[0, 2, 3])\n",
        "        cam = torch.zeros(activations.shape[2:], dtype=torch.float32)\n",
        "        for i, w in enumerate(weights):\n",
        "            cam += w * activations[0, i, :, :]\n",
        "        cam = torch.clamp(cam, min=0)\n",
        "        cam = cam / torch.max(cam)\n",
        "        return cam\n",
        "\n",
        "    def _remove_hooks(self):\n",
        "        for hook in self.hooks:\n",
        "            hook.remove()  # Remove each hook to avoid memory buildup\n",
        "        self.hooks.clear()\n",
        "\n",
        "grad_cam = GradCAM(model.visual)\n",
        "\n",
        "# Process each observation individually\n",
        "for i, observation in enumerate(observations):\n",
        "    if observation.photos:\n",
        "        # Save image and metadata\n",
        "        path = os.path.join(IMAGES_DIR, f\"{observation.id}.jpg\")\n",
        "        with observation.photos[0].open(size='medium') as infile:\n",
        "            with open(path, 'wb') as outfile:\n",
        "                outfile.write(infile.read())\n",
        "\n",
        "        taxon = observation.taxon.name if observation.taxon else 'Unknown'\n",
        "\n",
        "        # Load and preprocess the image to tensor\n",
        "        img = Image.open(path).convert('RGB')\n",
        "        tensor = preprocess_train(img).unsqueeze(0)  # Add batch dimension\n",
        "\n",
        "        # Make prediction\n",
        "        try:\n",
        "            prediction = classifier.predict(path, Rank.SPECIES, k=1)[0]\n",
        "            species, family = prediction['species'], prediction['family']\n",
        "        except Exception as e:\n",
        "            print(f\"Prediction failed for {path}: {e}\")\n",
        "            continue\n",
        "\n",
        "        # Automatically add new species to the index if not present\n",
        "        if species not in class_labels_to_index:\n",
        "            class_labels_to_index[species] = len(class_labels_to_index)\n",
        "\n",
        "        class_idx = class_labels_to_index[species]\n",
        "\n",
        "        # Generate Grad-CAM\n",
        "        try:\n",
        "            tensor.requires_grad_()\n",
        "            output = grad_cam.forward(tensor)\n",
        "            output[0, class_idx].backward()\n",
        "            grad_cam.save_gradients(tensor.grad)\n",
        "            cam = grad_cam.generate_cam(class_idx)\n",
        "\n",
        "            # Resize CAM to match the original image size\n",
        "            original_size = img.size\n",
        "            cam_resized = resize(cam.detach().cpu().numpy(), original_size[::-1], mode='reflect', anti_aliasing=True)\n",
        "\n",
        "            # Convert CAM to color map\n",
        "            cam_colormap = plt.cm.plasma(cam_resized)\n",
        "            cam_colormap = (cam_colormap[:, :, :3] * 255).astype(np.uint8)\n",
        "            cam_colormap_img = Image.fromarray(cam_colormap).resize(original_size, Image.BILINEAR)\n",
        "\n",
        "            # Overlay Grad-CAM on the original image\n",
        "            blended = Image.blend(img.convert('RGB'), cam_colormap_img, alpha=0.5)\n",
        "\n",
        "            # Save plots directly to PDF in Google Drive\n",
        "            pdf_path = os.path.join(OUTPUT_DIR, f\"{observation.id}_gradcam.pdf\")\n",
        "            with plt.ioff():\n",
        "                plt.figure(figsize=(12, 12))\n",
        "\n",
        "                plt.subplot(2, 2, 1)\n",
        "                plt.imshow(img)\n",
        "                plt.title('Image')\n",
        "\n",
        "                plt.subplot(2, 2, 2)\n",
        "                plt.imshow(cam_resized, cmap='plasma', interpolation='bilinear')\n",
        "                plt.colorbar()\n",
        "                plt.title('Grad-CAM (Plasma Colormap)')\n",
        "\n",
        "                plt.subplot(2, 2, 3)\n",
        "                plt.imshow(blended)\n",
        "                plt.title('Image + Grad-CAM Overlay')\n",
        "\n",
        "                plt.subplot(2, 2, 4)\n",
        "                plt.axis('off')  # Hide axes\n",
        "                text = f\"iNaturalist Taxon: {taxon}\\nBioCLIP Species: {species}\\nBioCLIP Family: {family}\"\n",
        "                plt.text(0.5, 0.5, text, ha='center', va='center', fontsize=12, wrap=True)\n",
        "                plt.title(\"Species Information\")\n",
        "\n",
        "                plt.savefig(pdf_path, format='pdf')\n",
        "                plt.close('all')\n",
        "\n",
        "            # Output results\n",
        "            print(f\"Processed image {i+1}/{MAX_IMAGES}: {path}\")\n",
        "            print(\"iNaturalist taxon:\", taxon)\n",
        "            print(\"BioCLIP species:\", species)\n",
        "            print(\"BioCLIP family:\", family)\n",
        "            print(\"\\n\")\n",
        "\n",
        "            # Clear tensors and free up memory\n",
        "            del tensor, output, cam, cam_resized, cam_colormap, cam_colormap_img, blended\n",
        "            torch.cuda.empty_cache()  # Use this if running on GPU\n",
        "            gc.collect()  # Force garbage collection to clear unused memory\n",
        "\n",
        "\n",
        "        except Exception as e:\n",
        "          print(f\"Error processing image {path}: {e}\")\n",
        "          continue\n"
      ]
    }
  ]
}